{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "327a536d53e84b8db9c87fd448bf2fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7f777f40a39418ca574e69a2a466dfc",
              "IPY_MODEL_ab8c7fc04cd24483ad453fbb77d92826",
              "IPY_MODEL_56be39164d6b4446a1beda57be553fa5"
            ],
            "layout": "IPY_MODEL_de875cc2dd6f4f6ca1ad256688afb079"
          }
        },
        "f7f777f40a39418ca574e69a2a466dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d224b4f7bc4cc88e85dc0950f01588",
            "placeholder": "​",
            "style": "IPY_MODEL_ce2e347eca0549bfb6723825dccb58e5",
            "value": "Loading experts: 100%"
          }
        },
        "ab8c7fc04cd24483ad453fbb77d92826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0902af406b114aa1922cb17b4e65938f",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_904c60670bb84762a59d54db308e1275",
            "value": 32
          }
        },
        "56be39164d6b4446a1beda57be553fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5726ef7d8c054a9d9b359fd6e1cde1ca",
            "placeholder": "​",
            "style": "IPY_MODEL_8c9d24e793c8464fb705597a357910b7",
            "value": " 32/32 [01:15&lt;00:00,  2.38s/it]"
          }
        },
        "de875cc2dd6f4f6ca1ad256688afb079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d224b4f7bc4cc88e85dc0950f01588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce2e347eca0549bfb6723825dccb58e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0902af406b114aa1922cb17b4e65938f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "904c60670bb84762a59d54db308e1275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5726ef7d8c054a9d9b359fd6e1cde1ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9d24e793c8464fb705597a357910b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mixtral in Colab\n",
        "\n",
        "Welcome! In this notebook you can run a quantized version of [Mixtral8x7B-Instruct](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1). This was made possible by quantizing the original model in mixed precision and implementing a MoE-specific offloading strategy.\n",
        "\n",
        "To learn more, read our [tech report](https://arxiv.org/abs/2312.17238) or check out the [repo](https://github.com/dvmazur/mixtral-offloading) on GitHub."
      ],
      "metadata": {
        "id": "OW1moHJ1TdhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import libraries"
      ],
      "metadata": {
        "id": "Y8MhvkC7TKEL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7qY7ebqX7T7"
      },
      "outputs": [],
      "source": [
        "# fix numpy in colab\n",
        "import numpy\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# fix triton in colab\n",
        "!export LC_ALL=\"en_US.UTF-8\"\n",
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig /usr/lib64-nvidia\n",
        "\n",
        "!git clone https://github.com/dvmazur/mixtral-offloading.git --quiet\n",
        "!cd mixtral-offloading && pip install -q -r requirements.txt\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"mixtral-offloading\")\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from hqq.core.quantize import BaseQuantizeConfig\n",
        "from huggingface_hub import snapshot_download\n",
        "from IPython.display import clear_output\n",
        "from tqdm.auto import trange\n",
        "from transformers import AutoConfig, AutoTokenizer\n",
        "from transformers.utils import logging as hf_logging\n",
        "\n",
        "from src.build_model import OffloadConfig, QuantConfig, build_model\n",
        "\n",
        "hf_logging.disable_progress_bar()"
      ],
      "metadata": {
        "id": "GgpjnV7fV49W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize model"
      ],
      "metadata": {
        "id": "OkSYibHcTQsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "quantized_model_name = \"lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "\n",
        "state_path = snapshot_download(quantized_model_name)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "offload_config = OffloadConfig(\n",
        "    main_size=config.num_local_experts * config.num_hidden_layers * 4 // 8,\n",
        "    offload_size=config.num_local_experts * config.num_hidden_layers * 4 // 8,\n",
        "    buffer_size=4,\n",
        "    offload_per_layer=4,\n",
        ")\n",
        "\n",
        "attn_config = BaseQuantizeConfig(\n",
        "    nbits=4,\n",
        "    group_size=64,\n",
        "    quant_zero=True,\n",
        "    quant_scale=True,\n",
        ")\n",
        "attn_config[\"scale_quant_params\"][\"group_size\"] = 256\n",
        "\n",
        "\n",
        "ffn_config = BaseQuantizeConfig(\n",
        "    nbits=2,\n",
        "    group_size=16,\n",
        "    quant_zero=True,\n",
        "    quant_scale=True,\n",
        ")\n",
        "\n",
        "quant_config = QuantConfig(ffn_config=ffn_config, attn_config=attn_config)\n",
        "\n",
        "\n",
        "offload_config = OffloadConfig(\n",
        "    main_size=config.num_local_experts * config.num_hidden_layers * 4 // 8,\n",
        "    offload_size=config.num_local_experts * config.num_hidden_layers * 4 // 8,\n",
        "    buffer_size=4,\n",
        "    offload_per_layer=4,\n",
        ")\n",
        "\n",
        "model = build_model(\n",
        "    device=device,\n",
        "    quant_config=quant_config,\n",
        "    offload_config=offload_config,\n",
        "    state_path=state_path,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "327a536d53e84b8db9c87fd448bf2fb0",
            "f7f777f40a39418ca574e69a2a466dfc",
            "ab8c7fc04cd24483ad453fbb77d92826",
            "56be39164d6b4446a1beda57be553fa5",
            "de875cc2dd6f4f6ca1ad256688afb079",
            "10d224b4f7bc4cc88e85dc0950f01588",
            "ce2e347eca0549bfb6723825dccb58e5",
            "0902af406b114aa1922cb17b4e65938f",
            "904c60670bb84762a59d54db308e1275",
            "5726ef7d8c054a9d9b359fd6e1cde1ca",
            "8c9d24e793c8464fb705597a357910b7"
          ]
        },
        "id": "_mIpePTMFyRY",
        "outputId": "afff0348-b4cd-4e7d-cdf7-9ab22792f588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading experts:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "327a536d53e84b8db9c87fd448bf2fb0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model"
      ],
      "metadata": {
        "id": "Z4hBFYtPTUzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "past_key_values = None\n",
        "sequence = None\n",
        "\n",
        "seq_len = 0\n",
        "while True:\n",
        "  print(\"User: \", end=\"\")\n",
        "  user_input = input()\n",
        "  print(\"\\n\")\n",
        "\n",
        "  user_entry = dict(role=\"user\", content=user_input)\n",
        "  input_ids = tokenizer.apply_chat_template([user_entry], return_tensors=\"pt\").to(device)\n",
        "\n",
        "  if past_key_values is None:\n",
        "    attention_mask = torch.ones_like(input_ids)\n",
        "  else:\n",
        "    seq_len = input_ids.size(1) + past_key_values[0][0][0].size(1)\n",
        "    attention_mask = torch.ones([1, seq_len - 1], dtype=torch.int, device=device)\n",
        "\n",
        "  print(\"Mixtral: \", end=\"\")\n",
        "  result = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    past_key_values=past_key_values,\n",
        "    streamer=streamer,\n",
        "    do_sample=True,\n",
        "    temperature=0.9,\n",
        "    top_p=0.9,\n",
        "    max_new_tokens=512,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    return_dict_in_generate=True,\n",
        "    output_hidden_states=True,\n",
        "  )\n",
        "  print(\"\\n\")\n",
        "\n",
        "  sequence = result[\"sequences\"]\n",
        "  past_key_values = result[\"past_key_values\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf4GkspecSm8",
        "outputId": "be5af5e9-171f-4f22-8ecf-819dc03b17fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hello, my name is Denis!\n",
            "\n",
            "\n",
            "Mixtral: Hello Denis! It's nice to meet you. How can I help you today? If you have any questions about a programming language, a coding concept, or a software tool, feel free to ask! I'm here to help.\n",
            "\n",
            "If you're new to the community, please check out our c [**helpful, pe**rfapthe rules, which are located in the header of **/r/learnprogramming** and the **/r/AskProgramming** subreddit. After that, I recommend checking out our **[wiki](https://reddit.com/r/learnprogramming/wiki/index)** for some excellent resources for learning to code. You can also [**join our chat**](https://reddit.com/r/learnprogramming/wiki/chat) to get help in real-time.\n",
            "\n",
            "For more specific questions, I recommend using the search function first to see if your question has already been answered. You can also use the **flair** system to filter for questions that are similar to yours. For example, if you have a question about a specific programming language, you can filter the results to only show posts with that flair.\n",
            "\n",
            "Lastly, if you're new to programming, I recommend checking out our **[Getting Started](https://reddit.com/r/learnprogramming/wiki/index#wiki_getting_started)** guide. It provides a lot of great resources to help you get started on your programming journey.\n",
            "\n",
            "I'm looking forward to helping you out in any way I can! Just let me know if you have any questions or need any help. Happy coding! 🤖👍\n",
            "\n",
            "\n",
            "User: I'd like to learn F#\n",
            "\n",
            "\n",
            "Mixtral: That's great! F# is a powerful and expressive programming language that combines the simplicity of functional programming with the performance of .NET.\n",
            "\n",
            "To get started with F#, I recommend checking out the following resources:\n",
            "\n",
            "1. **[F# Online Compiler](https://www.tryfsharp.org)** - This is an online F# compiler that allows you to write and execute F# code right in your browser. It's a great way to learn the basics of the language without having to install anything.\n",
            "\n",
            "2. **[F# Tutorials for Beginners](https://fsharpforfunandprofit.com/series/fsharp-for-beginners)** - This is a series of blog posts that introduce F# to beginners. It covers the basics of the language, and it's a great way to get started with F#.\n",
            "\n",
            "3. **[F# Koans](http://fsharpkareninblog.blogspot.com/2012/07/introduction-to-fsharp-interactive.html)** - This is a set of interactive F# exercises that will help you learn the language by solving puzzles.\n",
            "\n",
            "4. **[F# Learning Resources](https://fsharp.org/learn.html)** - This is a list of F# learning resources compiled by the F# Software Foundation. It includes books, tutorials, and courses that will help you learn F#.\n",
            "\n",
            "5. **[F# Community](https://fsharp.org/community.html)** - This is a list of F# communities where you can ask questions, share your knowledge, and meet other F# developers.\n",
            "\n",
            "I hope these resources help you get started with F#! It's a great language with a supportive community, and I'm sure you'll enjoy learning it. Good luck! 😊👍\n",
            "\n",
            "\n",
            "User: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEEPFruzqT5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}